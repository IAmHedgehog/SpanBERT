{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import importlib\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "from llm import LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'org:political/religious_affiliation', 'per:cause_of_death', 'org:founded_by', 'org:shareholders', 'per:parents', 'org:dissolved', 'per:countries_of_residence', 'org:founded', 'per:siblings', 'per:city_of_death', 'per:origin', 'per:stateorprovinces_of_residence', 'per:country_of_death', 'per:spouse', 'per:date_of_death', 'per:children', 'per:other_family', 'per:stateorprovince_of_death', 'per:stateorprovince_of_birth', 'per:religion', 'per:schools_attended', 'per:charges', 'per:date_of_birth', 'org:number_of_employees/members', 'per:cities_of_residence', 'per:country_of_birth'}\n",
      "3447\n"
     ]
    }
   ],
   "source": [
    "data = json.load(open('datasets/retacred/train.json'))\n",
    "\n",
    "re_stats = defaultdict(int)\n",
    "for sent in data:\n",
    "    re_stats[sent['relation']] += 1\n",
    "ignore_keys = set(['org:website', 'per:city_of_birth'])\n",
    "aug_keys = set()\n",
    "for key, value in sorted(re_stats.items(), key=lambda x: x[1]):\n",
    "    if value < 300 and key not in ignore_keys:\n",
    "        # print(f'---{key}: {value}')\n",
    "        aug_keys.add(key)\n",
    "print(aug_keys)\n",
    "aug_sents = [sent for sent in data if sent['relation'] in aug_keys]\n",
    "print(len(aug_sents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be026f1a7b794097869cf62a557d0b85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "llm = LLM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import aug\n",
    "\n",
    "\n",
    "importlib.reload(aug)\n",
    "\n",
    "template = \"\"\"\n",
    "You are an editor who is very good at paraphrasing sentences. Your task is rewrite a given sentence well keeping the original entities.\n",
    "\n",
    "In a sentence, two entities are nested in the sentence in the format of [[ entity ]].\n",
    "Rewrite the given sentence using each given entity exactly once and do not introduce other entities.\n",
    "Nest the original entities in the same format in the rewrited sentence.\n",
    "You can change the content inside the entity.\n",
    "\n",
    "%s\n",
    "\"\"\"\n",
    "\n",
    "encoded_sents = aug.get_encoded_sents(aug_sents)\n",
    "save_folder = 'augs'\n",
    "\n",
    "for relation, cur_encoded_sents in sorted(encoded_sents.items(), key=lambda x: len(x[1])):\n",
    "    print('--------> processing', relation, len(cur_encoded_sents))\n",
    "    file_name = f'{relation.replace(\"/\", \"--\")}.json'\n",
    "    save_path = os.path.join(save_folder, file_name)\n",
    "    if os.path.exists(save_path):\n",
    "        print(f'skip {relation} due to {save_path} exists')\n",
    "        continue\n",
    "    rewrited_sents = []\n",
    "    for encoded_sent, head_ent_type, tail_ent_type, head_ent, tail_ent in tqdm(cur_encoded_sents):\n",
    "        message = template % encoded_sent\n",
    "        rewrited_sent = aug.rewrite_sent(llm, message)\n",
    "        if rewrited_sent:\n",
    "            # print('*' * 30)\n",
    "            # print(encoded_sent)\n",
    "            # print(rewrited_sent)\n",
    "            rewrited_sents.append((rewrited_sent, head_ent_type, tail_ent_type, head_ent, tail_ent))\n",
    "    print(f'--------> {len(rewrited_sents)} sentences generated')\n",
    "    print('*' * 50)\n",
    "    with open(save_path, 'w') as af:\n",
    "        json.dump(rewrited_sents, af)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check how many sentences augmented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated 14104 sentences for 18\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from glob import glob\n",
    "\n",
    "aug_files = glob('augs/*.json')\n",
    "cnt = 0\n",
    "relations = set()\n",
    "for aug_file in aug_files:\n",
    "    cur_data = json.load(open(aug_file))\n",
    "    cnt += len(cur_data)\n",
    "    relation = os.path.basename(aug_file).split('_')[0]\n",
    "    relations.add(relation)\n",
    "print(f'generated {cnt} sentences for {len(relations)} relations')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### transform augmented sentences into target data format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rapidfuzz import fuzz\n",
    "\n",
    "def transform_aug_file(aug_file):\n",
    "    relation = os.path.basename(aug_file).rsplit('_', 1)[0].replace('--', '/')\n",
    "    cur_data = json.load(open(aug_file))\n",
    "    new_cur_data = []\n",
    "    for idx, (words, head_ent_type, tail_ent_type, head_words, tail_words) in enumerate(cur_data):\n",
    "        org_sent = ' '.join(words)\n",
    "        words, head_ent_type, tail_ent_type, head_words, tail_words = cur_data[idx]\n",
    "        # print('----->', ' '.join(words))\n",
    "        head_start = words.index('[[') - 0\n",
    "        head_end = words.index(']]') - 1\n",
    "        tail_start = words.index('[[', head_start+1) - 1\n",
    "        tail_end = words.index(']]', head_end+2) - 2\n",
    "        words.remove('[[')\n",
    "        words.remove(']]')\n",
    "\n",
    "        if head_start >= head_end or tail_start >= tail_end:\n",
    "            print('======>', org_sent)\n",
    "            continue\n",
    "\n",
    "        assert head_end < len(words)\n",
    "        assert tail_end < len(words)\n",
    "        assert head_start >= 0\n",
    "        assert tail_start >= 0\n",
    "        assert head_start < head_end\n",
    "        assert tail_start < tail_end\n",
    "\n",
    "        # print(relation, '---=======>', words[head_start: head_end])\n",
    "        # print(relation, '---=======>', words[tail_start: tail_end])\n",
    "        # print(relation, '---=======>', head_words)\n",
    "        # print(relation, '---=======>', tail_words)\n",
    "\n",
    "        cur_head_words = words[head_start: head_end]\n",
    "        cur_tail_words = words[tail_start: tail_end]\n",
    "        head_head_ratio = fuzz.ratio(' '.join(cur_head_words), ' '.join(head_words))\n",
    "        head_tail_ratio = fuzz.ratio(' '.join(cur_head_words), ' '.join(tail_words))\n",
    "        tail_head_ratio = fuzz.ratio(' '.join(cur_tail_words), ' '.join(head_words))\n",
    "        tail_tail_ratio = fuzz.ratio(' '.join(cur_tail_words), ' '.join(tail_words))\n",
    "        if head_head_ratio < head_tail_ratio:\n",
    "            head_start, head_end, tail_start, tail_end = tail_start, tail_end, head_start, head_end\n",
    "\n",
    "        sid = f'{os.path.basename(aug_file)[:-5]}_{idx}'\n",
    "        sent = {\n",
    "            'id': sid, 'token': words, 'subj_start': head_start, 'subj_end': head_end-1,\n",
    "            'obj_start': tail_start, 'obj_end': tail_end-1, 'relation': relation,\n",
    "            'subj_type': head_ent_type, 'obj_type': tail_ent_type}\n",
    "        new_cur_data.append(sent)\n",
    "    return new_cur_data\n",
    "\n",
    "aug_files = glob('augs/*.json')\n",
    "sents = []\n",
    "for aug_file in aug_files:\n",
    "    sents.extend(transform_aug_file(aug_file))\n",
    "\n",
    "train_data = json.load(open('datasets/retacred/train.json'))\n",
    "json.dump(sents+train_data, open('datasets/retacred_aug/train.json', 'w'))\n",
    "\n",
    "print(f'transformed {len(sents)}, total {len(sents+train_data)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check data consistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n",
      "40\n",
      "set()\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "org_stats = defaultdict(int)\n",
    "for sent in train_data:\n",
    "    org_stats[sent['relation']] += 1\n",
    "\n",
    "print(len(org_stats))\n",
    "\n",
    "stats = defaultdict(int)\n",
    "for sent in sents+train_data:\n",
    "    stats[sent['relation']] += 1\n",
    "\n",
    "print(len(stats))\n",
    "\n",
    "print(set(stats.keys()) - set(org_stats.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare test results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pred_stats(train_file, test_file, pred_file):\n",
    "    train_data = json.load(open(train_file))\n",
    "    test_data = json.load(open(test_file))\n",
    "    gt_id2label = {sent['id']: sent['relation'] for sent in test_data if sent['relation'] != 'no_relation'}\n",
    "    \n",
    "    train_stats = defaultdict(int)\n",
    "    for sent in train_data:\n",
    "        if sent['relation'] == 'no_relation':\n",
    "            continue\n",
    "        train_stats[sent['relation']] += 1\n",
    "\n",
    "    test_class_stats = defaultdict(set)\n",
    "    test_pos_sids = set()\n",
    "    for sent in test_data:\n",
    "        if sent['relation'] == 'no_relation':\n",
    "            continue\n",
    "        gt_id2label[sent['id']] = sent['relation']\n",
    "        test_class_stats[sent['relation']].add(sent['id'])\n",
    "        test_pos_sids.add((sent['id'], sent['relation']))\n",
    "\n",
    "    with open(pred_file) as pred_f:\n",
    "        lines = pred_f.readlines()\n",
    "    all_preds = set()\n",
    "    class_preds = defaultdict(set)\n",
    "    for line in lines:\n",
    "        sid, pred = line.strip().split()\n",
    "        if pred == 'no_relation':\n",
    "            continue\n",
    "        all_preds.add((sid, pred))\n",
    "        class_preds[pred].add(sid)\n",
    "\n",
    "    TP = len(all_preds & test_pos_sids)\n",
    "    FP = len(all_preds - test_pos_sids)\n",
    "    FN = len(test_pos_sids - all_preds)\n",
    "    # print('pred =========>', all_preds)\n",
    "    # print('GT =========>', test_pos_sids)\n",
    "    print(TP, FP, FN)\n",
    "    prec = TP / (TP + FP)\n",
    "    recall = TP / (TP + FN)\n",
    "    f1 = 2 * prec * recall / (prec + recall)\n",
    "\n",
    "    print(TP, FP, FN, prec, recall, f1)\n",
    "\n",
    "    stats = {'overall': {'TP': TP, 'FP': FP, 'FN': FN, 'support': TP+FN, 'prec': prec, 'recall': recall, 'f1': f1}}\n",
    "    for relation in test_class_stats.keys():\n",
    "        class_TP = len(class_preds[relation] & test_class_stats[relation])\n",
    "        class_FP = len(class_preds[relation] - test_class_stats[relation])\n",
    "        class_FN = len(test_class_stats[relation] - class_preds[relation])\n",
    "        # print(relation, '=====>', TP, FP, FN)\n",
    "        class_prec = class_TP / (class_TP + class_FP) if (class_TP + class_FP) else 0\n",
    "        class_recall = class_TP / (class_TP + class_FN) if (class_TP + class_FN) else 0\n",
    "        class_f1 = 2 * class_prec * class_recall / (class_prec + class_recall) if (class_prec + class_recall) else 0\n",
    "        stats[relation] = {'TP': class_TP, 'FP': class_FP, 'FN': class_FN, 'support': class_TP+class_FN, 'prec': class_prec, 'recall': class_recall, 'f1': class_f1}\n",
    "        # print(relation, '=====>', class_prec, class_recall, class_f1)\n",
    "\n",
    "    return train_stats, stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4614 907 1034\n",
      "4614 907 1034 0.8357181669987321 0.8169263456090652 0.8262154176739189\n"
     ]
    }
   ],
   "source": [
    "train_file = 'datasets/retacred/train.json'\n",
    "test_file = 'datasets/retacred/test.json'\n",
    "pred_file = 'tacred_dir/predictions.txt'\n",
    "train_stats, stats = get_pred_stats(train_file, test_file, pred_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4737 934 911\n",
      "4737 934 911 0.8353024157996826 0.8387039660056658 0.8369997349589186\n"
     ]
    }
   ],
   "source": [
    "train_file = 'datasets/retacred_aug/train.json'\n",
    "test_file = 'datasets/retacred_aug/test.json'\n",
    "pred_file = 'tacred_dir_aug/predictions.txt'\n",
    "aug_train_stats, aug_stats = get_pred_stats(train_file, test_file, pred_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------+-------------+--------------+--------+--------+--------+-----------------+---------+-----------+--------+\n",
      "|               Relation              | TestSupport | TrainSupport |  Prec  | Recall |   F1   | AugTrainSupport | AugPrec | AugRecall | AugF1  |\n",
      "+-------------------------------------+-------------+--------------+--------+--------+--------+-----------------+---------+-----------+--------+\n",
      "|               overall               |     5648    |    19704     | 0.8357 | 0.8169 | 0.8262 |      68672      |  0.8353 |   0.8387  | 0.837  |\n",
      "|         per:country_of_death        |      14     |      6       |   0    |  0.0   |   0    |        48       |   1.0   |   0.3571  | 0.5263 |\n",
      "|            org:dissolved            |      5      |      23      |   0    |  0.0   |   0    |       141       |   0.5   |    0.2    | 0.2857 |\n",
      "|         per:country_of_birth        |      0      |      25      |  0.0   |  0.0   |  0.0   |       182       |   0.0   |    0.0    |  0.0   |\n",
      "|     per:stateorprovince_of_birth    |      9      |      44      | 0.7273 | 0.8889 |  0.8   |       297       |  0.7273 |   0.8889  |  0.8   |\n",
      "|   org:number_of_employees/members   |      13     |      54      |  1.0   | 0.6923 | 0.8182 |       346       |   0.75  |   0.9231  | 0.8276 |\n",
      "|     per:stateorprovince_of_death    |      16     |      58      | 0.3636 |  0.25  | 0.2963 |       408       |   1.0   |    0.5    | 0.6667 |\n",
      "|          per:date_of_birth          |      7      |      69      | 0.7778 |  1.0   | 0.875  |       518       |  0.6364 |    1.0    | 0.7778 |\n",
      "|             per:religion            |      59     |      74      | 0.5385 | 0.1186 | 0.1944 |       516       |  0.7222 |   0.661   | 0.6903 |\n",
      "|             org:founded             |      34     |      80      | 0.8919 | 0.9706 | 0.9296 |       601       |  0.9189 |    1.0    | 0.9577 |\n",
      "|             per:charges             |     126     |      87      | 0.7619 | 0.7619 | 0.7619 |       695       |  0.7261 |   0.9048  | 0.8057 |\n",
      "|          per:city_of_birth          |      15     |      88      | 0.5333 | 0.5333 | 0.5333 |        88       |   0.8   |   0.5333  |  0.64  |\n",
      "|           org:shareholders          |      12     |      93      |  1.0   | 0.0833 | 0.1538 |       654       |   0.4   |   0.1667  | 0.2353 |\n",
      "|           per:other_family          |      52     |     105      |  1.0   | 0.7885 | 0.8817 |       822       |  0.746  |   0.9038  | 0.8174 |\n",
      "|            org:founded_by           |      84     |     107      | 0.9342 | 0.8452 | 0.8875 |       797       |  0.9103 |   0.8452  | 0.8765 |\n",
      "|          per:cause_of_death         |      50     |     114      | 0.7667 |  0.46  | 0.575  |       905       |  0.7576 |    0.5    | 0.6024 |\n",
      "|             org:website             |      30     |     119      | 0.5854 |  0.8   | 0.6761 |       119       |  0.575  |   0.7667  | 0.6571 |\n",
      "|          per:city_of_death          |      26     |     120      | 0.6667 | 0.5385 | 0.5957 |       836       |  0.7273 |   0.6154  | 0.6667 |\n",
      "|         per:schools_attended        |      33     |     142      | 0.9286 | 0.7879 | 0.8525 |       840       |  0.8929 |   0.7576  | 0.8197 |\n",
      "|          per:date_of_death          |      63     |     172      | 0.6623 | 0.8095 | 0.7286 |       1288      |  0.8361 |   0.8095  | 0.8226 |\n",
      "|             per:parents             |     106     |     182      | 0.7742 | 0.6792 | 0.7236 |       1324      |  0.7755 |   0.717   | 0.7451 |\n",
      "|       per:cities_of_residence       |     125     |     188      | 0.7864 | 0.648  | 0.7105 |       1362      |  0.6691 |   0.744   | 0.7045 |\n",
      "| org:political/religious_affiliation |      29     |     190      |  0.8   | 0.8276 | 0.8136 |       1302      |  0.7568 |   0.9655  | 0.8485 |\n",
      "|      per:countries_of_residence     |     148     |     201      | 0.703  | 0.4797 | 0.5703 |       1441      |  0.7287 |   0.6351  | 0.6787 |\n",
      "|             per:siblings            |      66     |     211      | 0.8286 | 0.8788 | 0.8529 |       1654      |   0.76  |   0.8636  | 0.8085 |\n",
      "|  per:stateorprovinces_of_residence  |      73     |     261      | 0.7895 | 0.6164 | 0.6923 |       261       |  0.7963 |   0.589   | 0.6772 |\n",
      "|              per:spouse             |      73     |     271      |  0.75  | 0.8219 | 0.7843 |       271       |  0.8382 |   0.7808  | 0.8085 |\n",
      "|             per:children            |      55     |     275      | 0.5094 | 0.4909 |  0.5   |       275       |  0.5217 |   0.4364  | 0.4752 |\n",
      "|              per:origin             |     115     |     295      | 0.7232 | 0.7043 | 0.7137 |       295       |  0.7611 |   0.7478  | 0.7544 |\n",
      "|    org:stateorprovince_of_branch    |      57     |     315      | 0.8491 | 0.7895 | 0.8182 |       315       |  0.7121 |   0.8246  | 0.7642 |\n",
      "|            org:member_of            |      64     |     365      | 0.6207 | 0.5625 | 0.5902 |       365       |  0.6515 |   0.6719  | 0.6615 |\n",
      "|               per:age               |     208     |     421      | 0.9126 | 0.9038 | 0.9082 |       421       |  0.9282 |   0.9327  | 0.9305 |\n",
      "|             org:members             |      63     |     560      | 0.7407 | 0.6349 | 0.6838 |       560       |  0.7903 |   0.7778  | 0.784  |\n",
      "|          org:city_of_branch         |     129     |     622      | 0.7969 | 0.7907 | 0.7938 |       622       |  0.7769 |   0.7287  | 0.752  |\n",
      "|        org:country_of_branch        |     166     |     891      | 0.7143 | 0.6627 | 0.6875 |       891       |  0.7303 |   0.6687  | 0.6981 |\n",
      "|         org:alternate_names         |     337     |     1319     | 0.8605 | 0.8605 | 0.8605 |       1319      |  0.861  |   0.8457  | 0.8533 |\n",
      "|      org:top_members/employees      |     295     |     1475     | 0.9038 | 0.8915 | 0.8976 |       1475      |  0.9024 |   0.878   |  0.89  |\n",
      "|           per:employee_of           |     332     |     2136     | 0.7838 | 0.7861 | 0.785  |       2136      |  0.7844 |   0.7892  | 0.7868 |\n",
      "|              per:title              |     523     |     2626     | 0.9145 | 0.9407 | 0.9274 |       2626      |  0.9202 |   0.9254  | 0.9228 |\n",
      "|             per:identity            |     2036    |     5320     | 0.8686 | 0.9062 | 0.887  |       5320      |  0.8762 |   0.9111  | 0.8933 |\n",
      "+-------------------------------------+-------------+--------------+--------+--------+--------+-----------------+---------+-----------+--------+\n"
     ]
    }
   ],
   "source": [
    "from prettytable import PrettyTable\n",
    "\n",
    "test_stats = defaultdict(int)\n",
    "test_data = json.load(open(test_file))\n",
    "for sent in test_data:\n",
    "    if sent['relation'] == 'no_relation':\n",
    "        continue\n",
    "    test_stats[sent['relation']] += 1\n",
    "test_stats['overall'] = sum(test_stats.values())\n",
    "aug_train_stats['overall'] = sum(aug_train_stats.values())\n",
    "\n",
    "# print('====>', len(stats), len(aug_stats), stats.keys())\n",
    "table = PrettyTable()\n",
    "table.field_names = ['Relation', 'TestSupport', 'TrainSupport', 'Prec', 'Recall', 'F1', 'AugTrainSupport', 'AugPrec', 'AugRecall', 'AugF1']\n",
    "for relation, train_support in [('overall', sum(train_stats.values()))]+sorted(train_stats.items(), key=lambda x: x[1]):\n",
    "    if relation == 'no_relation':\n",
    "        continue\n",
    "    row = [relation, test_stats[relation], train_support]\n",
    "    if relation in stats:\n",
    "        row.extend([round(stats[relation]['prec'], 4), round(stats[relation]['recall'], 4), round(stats[relation]['f1'], 4)])\n",
    "    else:\n",
    "        row.extend([0.0, 0.0, 0.0])\n",
    "    row.append(aug_train_stats[relation])\n",
    "    if relation in aug_stats:\n",
    "        row.extend([round(aug_stats[relation]['prec'], 4), round(aug_stats[relation]['recall'], 4), round(aug_stats[relation]['f1'], 4)])\n",
    "    else:\n",
    "        row.extend([0.0, 0.0, 0.0])\n",
    "    table.add_row(row)\n",
    "\n",
    "print(table)\n",
    "\n",
    "with open('table.csv', 'w', newline='') as f_output:\n",
    "    f_output.write(table.get_csv_string())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
