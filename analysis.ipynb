{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import importlib\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "from llm import LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'org:political/religious_affiliation', 'per:cause_of_death', 'org:founded_by', 'org:shareholders', 'per:parents', 'org:dissolved', 'per:countries_of_residence', 'org:founded', 'per:siblings', 'per:city_of_death', 'per:origin', 'per:stateorprovinces_of_residence', 'per:country_of_death', 'per:spouse', 'per:date_of_death', 'per:children', 'per:other_family', 'per:stateorprovince_of_death', 'per:stateorprovince_of_birth', 'per:religion', 'per:schools_attended', 'per:charges', 'per:date_of_birth', 'org:number_of_employees/members', 'per:cities_of_residence', 'per:country_of_birth'}\n",
      "3447\n"
     ]
    }
   ],
   "source": [
    "data = json.load(open('datasets/retacred/train.json'))\n",
    "\n",
    "re_stats = defaultdict(int)\n",
    "for sent in data:\n",
    "    re_stats[sent['relation']] += 1\n",
    "ignore_keys = set(['org:website', 'per:city_of_birth'])\n",
    "aug_keys = set()\n",
    "for key, value in sorted(re_stats.items(), key=lambda x: x[1]):\n",
    "    if value < 300 and key not in ignore_keys:\n",
    "        # print(f'---{key}: {value}')\n",
    "        aug_keys.add(key)\n",
    "print(aug_keys)\n",
    "aug_sents = [sent for sent in data if sent['relation'] in aug_keys]\n",
    "print(len(aug_sents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be026f1a7b794097869cf62a557d0b85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "llm = LLM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import aug\n",
    "\n",
    "\n",
    "importlib.reload(aug)\n",
    "\n",
    "template = \"\"\"\n",
    "You are an editor who is very good at reading sentence. Your task is rewrite a given sentence well keeping the original entities.\n",
    "\n",
    "In a sentence, each entity is nested in the sentence in the format of [[ entity ]].\n",
    "Rewrite the given sentence using each given entity exactly once and do not introduce other entities.\n",
    "Nest the original entities in the same format in the rewrited sentence.\n",
    "You change the content inside the entity.\n",
    "\n",
    "%s\n",
    "\"\"\"\n",
    "\n",
    "encoded_sents = aug.get_encoded_sents(aug_sents)\n",
    "save_folder = 'aug'\n",
    "\n",
    "for relation, cur_encoded_sents in sorted(encoded_sents.items(), key=lambda x: len(x[1])):\n",
    "    print('--------> processing', relation)\n",
    "    file_name = f'{relation.replace(\"/\", \"--\")}.json'\n",
    "    save_path = os.path.join(save_folder, file_name)\n",
    "    if os.path.exists(file_name):\n",
    "        continue\n",
    "    rewrited_sents = []\n",
    "    for encoded_sent in tqdm(cur_encoded_sents):\n",
    "        message = template % encoded_sent\n",
    "        rewrited_sent = aug.rewrite_sent(llm, message)\n",
    "        if rewrited_sent:\n",
    "            # print('*' * 30)\n",
    "            # print(encoded_sent)\n",
    "            # print(rewrited_sent)\n",
    "            rewrited_sents.append(rewrited_sent)\n",
    "    print(f'--------> {len(rewrited_sents)} sentences generated')\n",
    "    print('*' * 50)\n",
    "    with open(file_name, 'w') as af:\n",
    "        json.dump(rewrited_sents, af)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "433\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "\n",
    "aug_files = glob('augs/*.json')\n",
    "cnt = 0\n",
    "for aug_file in aug_files:\n",
    "    cur_data = json.load(open(aug_file))\n",
    "    cnt += len(cur_data)\n",
    "print(f'generated {cnt} sentences')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
